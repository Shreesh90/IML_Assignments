{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "c5f93114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "df = pd.read_csv(\"HousingPrice.csv\")\n",
    "\n",
    "Price = df['price']\n",
    "FloorArea = df['lotsize']\n",
    "NoOfBedrooms = df['bedrooms']\n",
    "NoOfBathrooms = df['bathrms']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de4ae8a",
   "metadata": {},
   "source": [
    "## Feature Scaling on FloorArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "c395a03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      5850\n",
       " 1      4000\n",
       " 2      3060\n",
       " 3      6650\n",
       " 4      6360\n",
       "        ... \n",
       " 541    4800\n",
       " 542    6000\n",
       " 543    6000\n",
       " 544    6000\n",
       " 545    6000\n",
       " Name: lotsize, Length: 546, dtype: int64,\n",
       " 0      0.048092\n",
       " 1     -0.079056\n",
       " 2     -0.143661\n",
       " 3      0.103075\n",
       " 4      0.083143\n",
       "          ...   \n",
       " 541   -0.024073\n",
       " 542    0.058401\n",
       " 543    0.058401\n",
       " 544    0.058401\n",
       " 545    0.058401\n",
       " Name: lotsize, Length: 546, dtype: float64)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FloorAreaMean = np.mean(FloorArea)\n",
    "FloorAreaMin = min(FloorArea)\n",
    "FloorAreaMax = max(FloorArea)\n",
    "FloorAreaScaled = (FloorArea - FloorAreaMean)/(FloorAreaMax - FloorAreaMin)\n",
    "FloorArea, FloorAreaScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "ddd393c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546,)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FloorAreaScaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7af067",
   "metadata": {},
   "source": [
    "##  Creating useful Valiables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "6fae8424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 13)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = df.shape\n",
    "n, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "1d1e1556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382, 164)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = math.floor(n * 0.70)\n",
    "n_test = n - n_train\n",
    "n_train, n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "3cd88860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 546)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [1] * n\n",
    "data_without_scaling = list(zip(col,FloorArea,NoOfBedrooms,NoOfBathrooms))\n",
    "data_scaling = list(zip(col,FloorAreaScaled,NoOfBedrooms,NoOfBathrooms))\n",
    "len(data_without_scaling), len(data_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "e61649eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, Y_train, X_test, Y_test without scaling\n",
    "X_train = data_without_scaling[:n_train]\n",
    "Y_train = Price[:n_train]\n",
    "\n",
    "X_test = data_without_scaling[n_train+1:]\n",
    "Y_test = Price[n_train+1:]\n",
    "\n",
    "# X_train, Y_train, X_test, Y_test with scaling\n",
    "X_train_scaling = data_scaling[:n_train]\n",
    "Y_train_scaling = Price[:n_train]\n",
    "\n",
    "X_test_scaling = data_scaling[n_train+1:]\n",
    "Y_test_scaling = Price[n_train+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "97dffdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1, 5850, 3, 1),\n",
       "  (1, 4000, 2, 1),\n",
       "  (1, 3060, 3, 1),\n",
       "  (1, 6650, 3, 1),\n",
       "  (1, 6360, 2, 1),\n",
       "  (1, 4160, 3, 1),\n",
       "  (1, 3880, 3, 2),\n",
       "  (1, 4160, 3, 1),\n",
       "  (1, 4800, 3, 1),\n",
       "  (1, 5500, 3, 2),\n",
       "  (1, 7200, 3, 2),\n",
       "  (1, 3000, 2, 1),\n",
       "  (1, 1700, 3, 1),\n",
       "  (1, 2880, 3, 1),\n",
       "  (1, 3600, 2, 1),\n",
       "  (1, 3185, 2, 1),\n",
       "  (1, 3300, 3, 1),\n",
       "  (1, 5200, 4, 1),\n",
       "  (1, 3450, 1, 1),\n",
       "  (1, 3986, 2, 2),\n",
       "  (1, 4785, 3, 1),\n",
       "  (1, 4510, 4, 2),\n",
       "  (1, 4000, 3, 1),\n",
       "  (1, 3934, 2, 1),\n",
       "  (1, 4960, 2, 1),\n",
       "  (1, 3000, 2, 1),\n",
       "  (1, 3800, 2, 1),\n",
       "  (1, 4960, 2, 1),\n",
       "  (1, 3000, 3, 1),\n",
       "  (1, 4500, 3, 1),\n",
       "  (1, 3500, 2, 1),\n",
       "  (1, 3500, 4, 1),\n",
       "  (1, 4000, 2, 1),\n",
       "  (1, 4500, 2, 1),\n",
       "  (1, 6360, 2, 1),\n",
       "  (1, 4500, 2, 1),\n",
       "  (1, 4032, 2, 1),\n",
       "  (1, 5170, 3, 1),\n",
       "  (1, 5400, 4, 2),\n",
       "  (1, 3150, 2, 2),\n",
       "  (1, 3745, 3, 1),\n",
       "  (1, 4520, 3, 1),\n",
       "  (1, 4640, 4, 1),\n",
       "  (1, 8580, 5, 3),\n",
       "  (1, 2000, 2, 1),\n",
       "  (1, 2160, 3, 1),\n",
       "  (1, 3040, 2, 1),\n",
       "  (1, 3090, 3, 1),\n",
       "  (1, 4960, 4, 1),\n",
       "  (1, 3350, 3, 1),\n",
       "  (1, 5300, 5, 2),\n",
       "  (1, 4100, 4, 1),\n",
       "  (1, 9166, 2, 1),\n",
       "  (1, 4040, 3, 1),\n",
       "  (1, 3630, 3, 3),\n",
       "  (1, 3620, 2, 1),\n",
       "  (1, 2400, 3, 1),\n",
       "  (1, 7260, 3, 2),\n",
       "  (1, 4400, 3, 1),\n",
       "  (1, 2400, 3, 1),\n",
       "  (1, 4120, 2, 1),\n",
       "  (1, 4750, 2, 1),\n",
       "  (1, 4280, 2, 1),\n",
       "  (1, 4820, 3, 1),\n",
       "  (1, 5500, 4, 1),\n",
       "  (1, 5500, 3, 1),\n",
       "  (1, 5040, 3, 1),\n",
       "  (1, 6000, 2, 1),\n",
       "  (1, 2500, 2, 1),\n",
       "  (1, 4095, 3, 1),\n",
       "  (1, 4095, 2, 1),\n",
       "  (1, 3150, 3, 1),\n",
       "  (1, 1836, 2, 1),\n",
       "  (1, 2475, 3, 1),\n",
       "  (1, 3210, 3, 1),\n",
       "  (1, 3180, 3, 1),\n",
       "  (1, 1650, 3, 1),\n",
       "  (1, 3180, 4, 1),\n",
       "  (1, 3180, 2, 2),\n",
       "  (1, 6360, 2, 1),\n",
       "  (1, 4240, 3, 1),\n",
       "  (1, 3240, 2, 1),\n",
       "  (1, 3650, 3, 1),\n",
       "  (1, 3240, 3, 1),\n",
       "  (1, 3780, 2, 1),\n",
       "  (1, 6480, 3, 1),\n",
       "  (1, 5850, 2, 1),\n",
       "  (1, 3150, 3, 2),\n",
       "  (1, 3000, 2, 1),\n",
       "  (1, 3090, 2, 1),\n",
       "  (1, 6060, 3, 1),\n",
       "  (1, 5900, 4, 2),\n",
       "  (1, 7420, 4, 1),\n",
       "  (1, 8500, 3, 2),\n",
       "  (1, 8050, 3, 1),\n",
       "  (1, 6800, 2, 1),\n",
       "  (1, 8250, 3, 1),\n",
       "  (1, 8250, 3, 1),\n",
       "  (1, 3500, 2, 1),\n",
       "  (1, 2835, 2, 1),\n",
       "  (1, 4500, 3, 2),\n",
       "  (1, 3300, 3, 3),\n",
       "  (1, 4320, 3, 1),\n",
       "  (1, 3500, 4, 2),\n",
       "  (1, 4992, 3, 2),\n",
       "  (1, 4600, 2, 1),\n",
       "  (1, 3720, 2, 1),\n",
       "  (1, 3680, 3, 2),\n",
       "  (1, 3000, 3, 2),\n",
       "  (1, 3750, 2, 1),\n",
       "  (1, 5076, 3, 1),\n",
       "  (1, 4500, 2, 1),\n",
       "  (1, 5000, 3, 1),\n",
       "  (1, 4260, 4, 1),\n",
       "  (1, 6540, 4, 2),\n",
       "  (1, 3700, 4, 1),\n",
       "  (1, 3760, 3, 1),\n",
       "  (1, 4000, 3, 2),\n",
       "  (1, 4300, 3, 2),\n",
       "  (1, 6840, 5, 1),\n",
       "  (1, 4400, 2, 1),\n",
       "  (1, 10500, 4, 2),\n",
       "  (1, 4400, 2, 1),\n",
       "  (1, 4840, 3, 1),\n",
       "  (1, 4120, 2, 1),\n",
       "  (1, 4260, 4, 2),\n",
       "  (1, 5960, 3, 3),\n",
       "  (1, 8800, 3, 2),\n",
       "  (1, 4560, 3, 2),\n",
       "  (1, 4600, 3, 2),\n",
       "  (1, 4840, 2, 1),\n",
       "  (1, 3850, 3, 1),\n",
       "  (1, 4900, 3, 1),\n",
       "  (1, 3850, 3, 1),\n",
       "  (1, 3760, 3, 1),\n",
       "  (1, 6000, 4, 2),\n",
       "  (1, 4370, 3, 1),\n",
       "  (1, 7700, 2, 1),\n",
       "  (1, 2990, 2, 1),\n",
       "  (1, 3750, 3, 1),\n",
       "  (1, 3000, 3, 1),\n",
       "  (1, 2650, 3, 1),\n",
       "  (1, 4500, 4, 2),\n",
       "  (1, 4500, 2, 1),\n",
       "  (1, 4500, 3, 1),\n",
       "  (1, 4500, 2, 1),\n",
       "  (1, 2175, 3, 1),\n",
       "  (1, 4500, 3, 2),\n",
       "  (1, 4800, 5, 2),\n",
       "  (1, 4600, 4, 1),\n",
       "  (1, 3450, 3, 1),\n",
       "  (1, 3000, 3, 1),\n",
       "  (1, 3600, 2, 2),\n",
       "  (1, 3600, 3, 1),\n",
       "  (1, 3750, 3, 1),\n",
       "  (1, 2610, 4, 3),\n",
       "  (1, 2953, 3, 1),\n",
       "  (1, 2747, 4, 2),\n",
       "  (1, 1905, 5, 1),\n",
       "  (1, 3968, 3, 1),\n",
       "  (1, 3162, 3, 1),\n",
       "  (1, 6000, 4, 1),\n",
       "  (1, 2910, 3, 1),\n",
       "  (1, 2135, 3, 2),\n",
       "  (1, 3120, 3, 1),\n",
       "  (1, 4075, 3, 1),\n",
       "  (1, 3410, 3, 1),\n",
       "  (1, 2800, 3, 1),\n",
       "  (1, 2684, 2, 1),\n",
       "  (1, 3100, 3, 1),\n",
       "  (1, 3630, 2, 1),\n",
       "  (1, 1950, 3, 1),\n",
       "  (1, 2430, 3, 1),\n",
       "  (1, 4320, 3, 1),\n",
       "  (1, 3036, 3, 1),\n",
       "  (1, 3630, 3, 2),\n",
       "  (1, 5400, 4, 1),\n",
       "  (1, 3420, 4, 2),\n",
       "  (1, 3180, 3, 2),\n",
       "  (1, 3660, 4, 1),\n",
       "  (1, 4410, 2, 1),\n",
       "  (1, 3990, 3, 1),\n",
       "  (1, 4340, 3, 1),\n",
       "  (1, 3510, 3, 1),\n",
       "  (1, 3420, 5, 1),\n",
       "  (1, 3420, 2, 1),\n",
       "  (1, 5495, 3, 1),\n",
       "  (1, 3480, 4, 1),\n",
       "  (1, 7424, 3, 1),\n",
       "  (1, 3460, 4, 1),\n",
       "  (1, 3630, 3, 1),\n",
       "  (1, 3630, 2, 1),\n",
       "  (1, 3480, 3, 1),\n",
       "  (1, 3460, 3, 2),\n",
       "  (1, 3180, 2, 1),\n",
       "  (1, 3635, 2, 1),\n",
       "  (1, 3960, 3, 1),\n",
       "  (1, 4350, 3, 1),\n",
       "  (1, 3930, 2, 1),\n",
       "  (1, 3570, 3, 1),\n",
       "  (1, 3600, 3, 1),\n",
       "  (1, 2520, 5, 2),\n",
       "  (1, 3480, 3, 1),\n",
       "  (1, 3180, 4, 2),\n",
       "  (1, 3290, 2, 1),\n",
       "  (1, 4000, 4, 2),\n",
       "  (1, 2325, 3, 1),\n",
       "  (1, 4350, 2, 1),\n",
       "  (1, 3540, 2, 1),\n",
       "  (1, 3960, 3, 1),\n",
       "  (1, 2640, 2, 1),\n",
       "  (1, 2700, 2, 1),\n",
       "  (1, 2700, 3, 1),\n",
       "  (1, 3180, 3, 1),\n",
       "  (1, 3500, 4, 1),\n",
       "  (1, 3630, 2, 1),\n",
       "  (1, 6000, 4, 3),\n",
       "  (1, 3150, 3, 1),\n",
       "  (1, 3792, 4, 1),\n",
       "  (1, 3510, 3, 1),\n",
       "  (1, 3120, 3, 1),\n",
       "  (1, 3000, 4, 1),\n",
       "  (1, 4200, 3, 1),\n",
       "  (1, 2817, 4, 2),\n",
       "  (1, 3240, 4, 1),\n",
       "  (1, 2800, 3, 2),\n",
       "  (1, 3816, 2, 1),\n",
       "  (1, 3185, 2, 1),\n",
       "  (1, 6321, 3, 1),\n",
       "  (1, 3650, 3, 2),\n",
       "  (1, 4700, 4, 1),\n",
       "  (1, 6615, 4, 2),\n",
       "  (1, 3850, 3, 1),\n",
       "  (1, 3970, 1, 1),\n",
       "  (1, 3000, 2, 1),\n",
       "  (1, 4352, 4, 1),\n",
       "  (1, 3630, 4, 1),\n",
       "  (1, 3600, 6, 1),\n",
       "  (1, 3000, 2, 1),\n",
       "  (1, 3000, 4, 1),\n",
       "  (1, 2787, 4, 2),\n",
       "  (1, 3000, 2, 1),\n",
       "  (1, 4770, 3, 1),\n",
       "  (1, 3649, 2, 1),\n",
       "  (1, 3970, 3, 1),\n",
       "  (1, 2910, 2, 1),\n",
       "  (1, 3480, 2, 1),\n",
       "  (1, 6615, 3, 1),\n",
       "  (1, 3500, 2, 1),\n",
       "  (1, 3450, 3, 1),\n",
       "  (1, 3450, 3, 1),\n",
       "  (1, 3520, 2, 2),\n",
       "  (1, 6930, 4, 1),\n",
       "  (1, 4600, 3, 2),\n",
       "  (1, 4360, 4, 1),\n",
       "  (1, 3450, 3, 1),\n",
       "  (1, 4410, 4, 3),\n",
       "  (1, 4600, 2, 2),\n",
       "  (1, 3640, 2, 1),\n",
       "  (1, 6000, 2, 1),\n",
       "  (1, 5400, 4, 1),\n",
       "  (1, 3640, 4, 1),\n",
       "  (1, 3640, 2, 1),\n",
       "  (1, 4040, 2, 1),\n",
       "  (1, 3640, 2, 1),\n",
       "  (1, 3640, 2, 1),\n",
       "  (1, 5640, 2, 1),\n",
       "  (1, 3600, 2, 1),\n",
       "  (1, 3600, 2, 1),\n",
       "  (1, 4632, 4, 1),\n",
       "  (1, 3640, 3, 2),\n",
       "  (1, 4900, 2, 1),\n",
       "  (1, 4510, 4, 1),\n",
       "  (1, 4100, 2, 2),\n",
       "  (1, 3640, 3, 1),\n",
       "  (1, 5680, 3, 1),\n",
       "  (1, 6300, 3, 1),\n",
       "  (1, 4000, 3, 1),\n",
       "  (1, 3960, 3, 1),\n",
       "  (1, 5960, 3, 1),\n",
       "  (1, 5830, 2, 1),\n",
       "  (1, 4500, 4, 2),\n",
       "  (1, 4100, 3, 2),\n",
       "  (1, 6750, 2, 1),\n",
       "  (1, 9000, 3, 1),\n",
       "  (1, 2550, 3, 1),\n",
       "  (1, 7152, 3, 1),\n",
       "  (1, 6450, 4, 1),\n",
       "  (1, 3360, 2, 1),\n",
       "  (1, 3264, 2, 1),\n",
       "  (1, 4000, 3, 1),\n",
       "  (1, 4000, 3, 1),\n",
       "  (1, 3069, 2, 1),\n",
       "  (1, 4040, 2, 1),\n",
       "  (1, 4040, 2, 1),\n",
       "  (1, 3185, 2, 1),\n",
       "  (1, 5900, 2, 1),\n",
       "  (1, 3120, 3, 1),\n",
       "  (1, 5450, 2, 1),\n",
       "  (1, 4040, 2, 1),\n",
       "  (1, 4080, 2, 1),\n",
       "  (1, 8080, 3, 1),\n",
       "  (1, 4040, 2, 1),\n",
       "  (1, 4080, 3, 1),\n",
       "  (1, 5800, 3, 1),\n",
       "  (1, 5885, 2, 1),\n",
       "  (1, 9667, 4, 2),\n",
       "  (1, 3420, 4, 2),\n",
       "  (1, 5800, 2, 1),\n",
       "  (1, 7600, 4, 1),\n",
       "  (1, 5400, 3, 1),\n",
       "  (1, 4995, 4, 2),\n",
       "  (1, 3000, 3, 1),\n",
       "  (1, 5500, 3, 2),\n",
       "  (1, 6450, 3, 2),\n",
       "  (1, 6210, 4, 1),\n",
       "  (1, 5000, 3, 1),\n",
       "  (1, 5000, 3, 1),\n",
       "  (1, 5828, 4, 1),\n",
       "  (1, 5200, 3, 1),\n",
       "  (1, 5500, 3, 1),\n",
       "  (1, 6350, 3, 2),\n",
       "  (1, 8250, 3, 2),\n",
       "  (1, 6000, 3, 1),\n",
       "  (1, 7700, 3, 2),\n",
       "  (1, 8880, 3, 2),\n",
       "  (1, 8880, 2, 1),\n",
       "  (1, 6480, 3, 2),\n",
       "  (1, 7000, 3, 2),\n",
       "  (1, 8875, 3, 1),\n",
       "  (1, 7155, 3, 2),\n",
       "  (1, 8960, 4, 4),\n",
       "  (1, 7350, 2, 1),\n",
       "  (1, 3850, 2, 1),\n",
       "  (1, 7000, 3, 1),\n",
       "  (1, 7770, 2, 1),\n",
       "  (1, 7440, 3, 2),\n",
       "  (1, 7500, 3, 3),\n",
       "  (1, 8100, 4, 1),\n",
       "  (1, 3900, 3, 1),\n",
       "  (1, 2970, 3, 1),\n",
       "  (1, 3000, 3, 1),\n",
       "  (1, 10500, 2, 1),\n",
       "  (1, 5500, 3, 2),\n",
       "  (1, 4500, 3, 1),\n",
       "  (1, 3850, 3, 1),\n",
       "  (1, 4130, 3, 2),\n",
       "  (1, 4046, 3, 1),\n",
       "  (1, 4079, 3, 1),\n",
       "  (1, 4000, 3, 1),\n",
       "  (1, 9860, 3, 1),\n",
       "  (1, 7000, 3, 1),\n",
       "  (1, 7980, 3, 1),\n",
       "  (1, 6800, 2, 1),\n",
       "  (1, 4300, 6, 2),\n",
       "  (1, 10269, 3, 1),\n",
       "  (1, 6100, 3, 1),\n",
       "  (1, 6420, 3, 2),\n",
       "  (1, 12090, 4, 2),\n",
       "  (1, 6600, 3, 1),\n",
       "  (1, 6600, 4, 2),\n",
       "  (1, 8580, 4, 3),\n",
       "  (1, 9960, 3, 2),\n",
       "  (1, 10700, 3, 1),\n",
       "  (1, 15600, 3, 1),\n",
       "  (1, 13200, 2, 1),\n",
       "  (1, 9000, 4, 2),\n",
       "  (1, 7950, 5, 2),\n",
       "  (1, 16200, 5, 3),\n",
       "  (1, 6100, 3, 2),\n",
       "  (1, 6360, 3, 1),\n",
       "  (1, 6420, 3, 1),\n",
       "  (1, 6360, 4, 2),\n",
       "  (1, 6540, 4, 2),\n",
       "  (1, 6420, 3, 2),\n",
       "  (1, 6550, 4, 2),\n",
       "  (1, 5750, 3, 2),\n",
       "  (1, 7420, 4, 2),\n",
       "  (1, 7160, 3, 1),\n",
       "  (1, 4000, 3, 2),\n",
       "  (1, 9000, 4, 2),\n",
       "  (1, 6550, 3, 1)],\n",
       " [(1, 0.0480917135556311, 3, 1),\n",
       "  (1, -0.07905605276739296, 2, 1),\n",
       "  (1, -0.14366086376395654, 3, 1),\n",
       "  (1, 0.10307453142504691, 3, 1),\n",
       "  (1, 0.08314325994738367, 2, 1),\n",
       "  (1, -0.06805948919350979, 3, 1),\n",
       "  (1, -0.08730347544780533, 3, 2),\n",
       "  (1, -0.06805948919350979, 3, 1),\n",
       "  (1, -0.02407323489797715, 3, 1),\n",
       "  (1, 0.02403673073776168, 3, 2),\n",
       "  (1, 0.14087521871027028, 3, 2),\n",
       "  (1, -0.1477845751041627, 2, 1),\n",
       "  (1, -0.2371316541419634, 3, 1),\n",
       "  (1, -0.15603199778457508, 3, 1),\n",
       "  (1, -0.10654746170210086, 2, 1),\n",
       "  (1, -0.13506979847186032, 2, 1),\n",
       "  (1, -0.1271660184031318, 3, 1),\n",
       "  (1, 0.0034181740367307534, 4, 1),\n",
       "  (1, -0.11685674005261633, 1, 1),\n",
       "  (1, -0.08001825208010774, 2, 2),\n",
       "  (1, -0.025104162733028696, 3, 1),\n",
       "  (1, -0.04400450637564038, 4, 2),\n",
       "  (1, -0.07905605276739296, 3, 1),\n",
       "  (1, -0.08359213524161976, 2, 1),\n",
       "  (1, -0.01307667132409399, 2, 1),\n",
       "  (1, -0.1477845751041627, 2, 1),\n",
       "  (1, -0.09280175723474691, 2, 1),\n",
       "  (1, -0.01307667132409399, 2, 1),\n",
       "  (1, -0.1477845751041627, 3, 1),\n",
       "  (1, -0.04469179159900808, 3, 1),\n",
       "  (1, -0.11342031393577784, 2, 1),\n",
       "  (1, -0.11342031393577784, 4, 1),\n",
       "  (1, -0.07905605276739296, 2, 1),\n",
       "  (1, -0.04469179159900808, 2, 1),\n",
       "  (1, 0.08314325994738367, 2, 1),\n",
       "  (1, -0.04469179159900808, 2, 1),\n",
       "  (1, -0.07685674005261632, 2, 1),\n",
       "  (1, 0.0013563183666276605, 3, 1),\n",
       "  (1, 0.017163878504084705, 4, 2),\n",
       "  (1, -0.13747529675364725, 2, 2),\n",
       "  (1, -0.09658182596326925, 3, 1),\n",
       "  (1, -0.043317221152272684, 3, 1),\n",
       "  (1, -0.035069798471860314, 4, 1),\n",
       "  (1, 0.23572057953501255, 5, 3),\n",
       "  (1, -0.21651309744093247, 2, 1),\n",
       "  (1, -0.20551653386704932, 3, 1),\n",
       "  (1, -0.14503543421069193, 2, 1),\n",
       "  (1, -0.14159900809385345, 3, 1),\n",
       "  (1, -0.01307667132409399, 4, 1),\n",
       "  (1, -0.12372959228629331, 3, 1),\n",
       "  (1, 0.01029102627040773, 5, 2),\n",
       "  (1, -0.07218320053371598, 4, 1),\n",
       "  (1, 0.2759954936243596, 2, 1),\n",
       "  (1, -0.07630691187392216, 3, 1),\n",
       "  (1, -0.10448560603199777, 3, 3),\n",
       "  (1, -0.10517289125536547, 2, 1),\n",
       "  (1, -0.18902168850622458, 3, 1),\n",
       "  (1, 0.14499893005047645, 3, 2),\n",
       "  (1, -0.05156464383268505, 3, 1),\n",
       "  (1, -0.18902168850622458, 3, 1),\n",
       "  (1, -0.07080863008698059, 2, 1),\n",
       "  (1, -0.02750966101481564, 2, 1),\n",
       "  (1, -0.05981206651309742, 2, 1),\n",
       "  (1, -0.022698664451241756, 3, 1),\n",
       "  (1, 0.02403673073776168, 4, 1),\n",
       "  (1, 0.02403673073776168, 3, 1),\n",
       "  (1, -0.007578389537152408, 3, 1),\n",
       "  (1, 0.05840099190614656, 2, 1),\n",
       "  (1, -0.1821488362725476, 2, 1),\n",
       "  (1, -0.07252684314539982, 3, 1),\n",
       "  (1, -0.07252684314539982, 2, 1),\n",
       "  (1, -0.13747529675364725, 3, 1),\n",
       "  (1, -0.22778457510416272, 2, 1),\n",
       "  (1, -0.18386704933096684, 3, 1),\n",
       "  (1, -0.13335158541344108, 3, 1),\n",
       "  (1, -0.13541344108354417, 3, 1),\n",
       "  (1, -0.2405680802588019, 3, 1),\n",
       "  (1, -0.13541344108354417, 4, 1),\n",
       "  (1, -0.13541344108354417, 2, 2),\n",
       "  (1, 0.08314325994738367, 2, 1),\n",
       "  (1, -0.06256120740656822, 3, 1),\n",
       "  (1, -0.13128972974333797, 2, 1),\n",
       "  (1, -0.10311103558526237, 3, 1),\n",
       "  (1, -0.13128972974333797, 3, 1),\n",
       "  (1, -0.0941763276814823, 2, 1),\n",
       "  (1, 0.09139068262779605, 3, 1),\n",
       "  (1, 0.0480917135556311, 2, 1),\n",
       "  (1, -0.13747529675364725, 3, 2),\n",
       "  (1, -0.1477845751041627, 2, 1),\n",
       "  (1, -0.14159900809385345, 2, 1),\n",
       "  (1, 0.06252470324635274, 3, 1),\n",
       "  (1, 0.05152813967246959, 4, 2),\n",
       "  (1, 0.15599549362435963, 4, 1),\n",
       "  (1, 0.23022229774807096, 3, 2),\n",
       "  (1, 0.19929446269652457, 3, 1),\n",
       "  (1, 0.11338380977556237, 2, 1),\n",
       "  (1, 0.21304016716387852, 3, 1),\n",
       "  (1, 0.21304016716387852, 3, 1),\n",
       "  (1, -0.11342031393577784, 2, 1),\n",
       "  (1, -0.15912478128972973, 2, 1),\n",
       "  (1, -0.04469179159900808, 3, 2),\n",
       "  (1, -0.1271660184031318, 3, 3),\n",
       "  (1, -0.057062925619626635, 3, 1),\n",
       "  (1, -0.11342031393577784, 4, 2),\n",
       "  (1, -0.010877358609317357, 3, 2),\n",
       "  (1, -0.0378189393653311, 2, 1),\n",
       "  (1, -0.09830003902168849, 2, 1),\n",
       "  (1, -0.10104917991515928, 3, 2),\n",
       "  (1, -0.1477845751041627, 3, 2),\n",
       "  (1, -0.0962381833515854, 2, 1),\n",
       "  (1, -0.0051041627330286965, 3, 1),\n",
       "  (1, -0.04469179159900808, 2, 1),\n",
       "  (1, -0.010327530430623198, 3, 1),\n",
       "  (1, -0.06118663695983282, 4, 1),\n",
       "  (1, 0.09551439396800224, 4, 2),\n",
       "  (1, -0.09967460946842388, 4, 1),\n",
       "  (1, -0.0955508981282177, 3, 1),\n",
       "  (1, -0.07905605276739296, 3, 2),\n",
       "  (1, -0.05843749606636203, 3, 2),\n",
       "  (1, 0.11613295066903316, 5, 1),\n",
       "  (1, -0.05156464383268505, 2, 1),\n",
       "  (1, 0.3676793424216105, 4, 2),\n",
       "  (1, -0.05156464383268505, 2, 1),\n",
       "  (1, -0.02132409400450636, 3, 1),\n",
       "  (1, -0.07080863008698059, 2, 1),\n",
       "  (1, -0.06118663695983282, 4, 2),\n",
       "  (1, 0.05565185101267577, 3, 3),\n",
       "  (1, 0.25084085444910187, 3, 2),\n",
       "  (1, -0.040568080258801896, 3, 2),\n",
       "  (1, -0.0378189393653311, 3, 2),\n",
       "  (1, -0.02132409400450636, 2, 1),\n",
       "  (1, -0.08936533111790843, 3, 1),\n",
       "  (1, -0.017200382664300174, 3, 1),\n",
       "  (1, -0.08936533111790843, 3, 1),\n",
       "  (1, -0.0955508981282177, 3, 1),\n",
       "  (1, 0.05840099190614656, 4, 2),\n",
       "  (1, -0.053626499502788146, 3, 1),\n",
       "  (1, 0.17523947987865515, 2, 1),\n",
       "  (1, -0.1484718603275304, 2, 1),\n",
       "  (1, -0.0962381833515854, 3, 1),\n",
       "  (1, -0.1477845751041627, 3, 1),\n",
       "  (1, -0.17183955792203212, 3, 1),\n",
       "  (1, -0.04469179159900808, 4, 2),\n",
       "  (1, -0.04469179159900808, 2, 1),\n",
       "  (1, -0.04469179159900808, 3, 1),\n",
       "  (1, -0.04469179159900808, 2, 1),\n",
       "  (1, -0.20448560603199778, 3, 1),\n",
       "  (1, -0.04469179159900808, 3, 2),\n",
       "  (1, -0.02407323489797715, 5, 2),\n",
       "  (1, -0.0378189393653311, 4, 1),\n",
       "  (1, -0.11685674005261633, 3, 1),\n",
       "  (1, -0.1477845751041627, 3, 1),\n",
       "  (1, -0.10654746170210086, 2, 2),\n",
       "  (1, -0.10654746170210086, 3, 1),\n",
       "  (1, -0.0962381833515854, 3, 1),\n",
       "  (1, -0.17458869881550293, 4, 3),\n",
       "  (1, -0.15101481565399089, 3, 1),\n",
       "  (1, -0.16517289125536547, 4, 2),\n",
       "  (1, -0.2230423070629256, 5, 1),\n",
       "  (1, -0.08125536548216959, 3, 1),\n",
       "  (1, -0.136650554485606, 3, 1),\n",
       "  (1, 0.05840099190614656, 4, 1),\n",
       "  (1, -0.153970142114472, 3, 1),\n",
       "  (1, -0.20723474692546856, 3, 2),\n",
       "  (1, -0.13953715242375034, 3, 1),\n",
       "  (1, -0.07390141359213523, 3, 1),\n",
       "  (1, -0.11960588094608711, 3, 1),\n",
       "  (1, -0.16153027957151667, 3, 1),\n",
       "  (1, -0.16950278816258196, 2, 1),\n",
       "  (1, -0.14091172287048573, 3, 1),\n",
       "  (1, -0.10448560603199777, 2, 1),\n",
       "  (1, -0.21994952355777098, 3, 1),\n",
       "  (1, -0.18695983283612147, 3, 1),\n",
       "  (1, -0.057062925619626635, 3, 1),\n",
       "  (1, -0.145310348300039, 3, 1),\n",
       "  (1, -0.10448560603199777, 3, 2),\n",
       "  (1, 0.017163878504084705, 4, 1),\n",
       "  (1, -0.11891859572271941, 4, 2),\n",
       "  (1, -0.13541344108354417, 3, 2),\n",
       "  (1, -0.10242375036189467, 4, 1),\n",
       "  (1, -0.05087735860931736, 2, 1),\n",
       "  (1, -0.07974333799076065, 3, 1),\n",
       "  (1, -0.05568835517289124, 3, 1),\n",
       "  (1, -0.11273302871241014, 3, 1),\n",
       "  (1, -0.11891859572271941, 5, 1),\n",
       "  (1, -0.11891859572271941, 2, 1),\n",
       "  (1, 0.023693088126077833, 3, 1),\n",
       "  (1, -0.11479488438251323, 4, 1),\n",
       "  (1, 0.1562704077137067, 3, 1),\n",
       "  (1, -0.11616945482924863, 4, 1),\n",
       "  (1, -0.10448560603199777, 3, 1),\n",
       "  (1, -0.10448560603199777, 2, 1),\n",
       "  (1, -0.11479488438251323, 3, 1),\n",
       "  (1, -0.11616945482924863, 3, 2),\n",
       "  (1, -0.13541344108354417, 2, 1),\n",
       "  (1, -0.10414196342031393, 2, 1),\n",
       "  (1, -0.08180519366086375, 3, 1),\n",
       "  (1, -0.05500106994952354, 3, 1),\n",
       "  (1, -0.08386704933096684, 2, 1),\n",
       "  (1, -0.10860931737220396, 3, 1),\n",
       "  (1, -0.10654746170210086, 3, 1),\n",
       "  (1, -0.1807742658258122, 5, 2),\n",
       "  (1, -0.11479488438251323, 3, 1),\n",
       "  (1, -0.13541344108354417, 4, 2),\n",
       "  (1, -0.1278533036264995, 2, 1),\n",
       "  (1, -0.07905605276739296, 4, 2),\n",
       "  (1, -0.1941763276814823, 3, 1),\n",
       "  (1, -0.05500106994952354, 2, 1),\n",
       "  (1, -0.11067117304230704, 2, 1),\n",
       "  (1, -0.08180519366086375, 3, 1),\n",
       "  (1, -0.17252684314539984, 2, 1),\n",
       "  (1, -0.16840313180519365, 2, 1),\n",
       "  (1, -0.16840313180519365, 3, 1),\n",
       "  (1, -0.13541344108354417, 3, 1),\n",
       "  (1, -0.11342031393577784, 4, 1),\n",
       "  (1, -0.10448560603199777, 2, 1),\n",
       "  (1, 0.05840099190614656, 4, 3),\n",
       "  (1, -0.13747529675364725, 3, 1),\n",
       "  (1, -0.09335158541344107, 4, 1),\n",
       "  (1, -0.11273302871241014, 3, 1),\n",
       "  (1, -0.13953715242375034, 3, 1),\n",
       "  (1, -0.1477845751041627, 4, 1),\n",
       "  (1, -0.06531034830003901, 3, 1),\n",
       "  (1, -0.16036189469179157, 4, 2),\n",
       "  (1, -0.13128972974333797, 4, 1),\n",
       "  (1, -0.16153027957151667, 3, 2),\n",
       "  (1, -0.0917021008773586, 2, 1),\n",
       "  (1, -0.13506979847186032, 2, 1),\n",
       "  (1, 0.08046284757624965, 3, 1),\n",
       "  (1, -0.10311103558526237, 3, 2),\n",
       "  (1, -0.030946087131654126, 4, 1),\n",
       "  (1, 0.10066903314325996, 4, 2),\n",
       "  (1, -0.08936533111790843, 3, 1),\n",
       "  (1, -0.08111790843749606, 1, 1),\n",
       "  (1, -0.1477845751041627, 2, 1),\n",
       "  (1, -0.05486361290485, 4, 1),\n",
       "  (1, -0.10448560603199777, 4, 1),\n",
       "  (1, -0.10654746170210086, 6, 1),\n",
       "  (1, -0.1477845751041627, 2, 1),\n",
       "  (1, -0.1477845751041627, 4, 1),\n",
       "  (1, -0.1624237503618947, 4, 2),\n",
       "  (1, -0.1477845751041627, 2, 1),\n",
       "  (1, -0.026135090568080242, 3, 1),\n",
       "  (1, -0.10317976410759915, 2, 1),\n",
       "  (1, -0.08111790843749606, 3, 1),\n",
       "  (1, -0.153970142114472, 2, 1),\n",
       "  (1, -0.11479488438251323, 2, 1),\n",
       "  (1, 0.10066903314325996, 3, 1),\n",
       "  (1, -0.11342031393577784, 2, 1),\n",
       "  (1, -0.11685674005261633, 3, 1),\n",
       "  (1, -0.11685674005261633, 3, 1),\n",
       "  (1, -0.11204574348904245, 2, 2),\n",
       "  (1, 0.12231851767934243, 4, 1),\n",
       "  (1, -0.0378189393653311, 3, 2),\n",
       "  (1, -0.05431378472615585, 4, 1),\n",
       "  (1, -0.11685674005261633, 3, 1),\n",
       "  (1, -0.05087735860931736, 4, 3),\n",
       "  (1, -0.0378189393653311, 2, 2),\n",
       "  (1, -0.10379832080863007, 2, 1),\n",
       "  (1, 0.05840099190614656, 2, 1),\n",
       "  (1, 0.017163878504084705, 4, 1),\n",
       "  (1, -0.10379832080863007, 4, 1),\n",
       "  (1, -0.10379832080863007, 2, 1),\n",
       "  (1, -0.07630691187392216, 2, 1),\n",
       "  (1, -0.10379832080863007, 2, 1),\n",
       "  (1, -0.10379832080863007, 2, 1),\n",
       "  (1, 0.033658723864909444, 2, 1),\n",
       "  (1, -0.10654746170210086, 2, 1),\n",
       "  (1, -0.10654746170210086, 2, 1),\n",
       "  (1, -0.03561962665055447, 4, 1),\n",
       "  (1, -0.10379832080863007, 3, 2),\n",
       "  (1, -0.017200382664300174, 2, 1),\n",
       "  (1, -0.04400450637564038, 4, 1),\n",
       "  (1, -0.07218320053371598, 2, 2),\n",
       "  (1, -0.10379832080863007, 3, 1),\n",
       "  (1, 0.03640786475838024, 3, 1),\n",
       "  (1, 0.07901954860717748, 3, 1),\n",
       "  (1, -0.07905605276739296, 3, 1),\n",
       "  (1, -0.08180519366086375, 3, 1),\n",
       "  (1, 0.05565185101267577, 3, 1),\n",
       "  (1, 0.0467171431088957, 2, 1),\n",
       "  (1, -0.04469179159900808, 4, 2),\n",
       "  (1, -0.07218320053371598, 3, 2),\n",
       "  (1, 0.10994738365872388, 2, 1),\n",
       "  (1, 0.2645865589164558, 3, 1),\n",
       "  (1, -0.1787124101557091, 3, 1),\n",
       "  (1, 0.13757624963810533, 3, 1),\n",
       "  (1, 0.08932882695769295, 4, 1),\n",
       "  (1, -0.1230423070629256, 2, 1),\n",
       "  (1, -0.1296402452072555, 2, 1),\n",
       "  (1, -0.07905605276739296, 3, 1),\n",
       "  (1, -0.07905605276739296, 3, 1),\n",
       "  (1, -0.14304230706292562, 2, 1),\n",
       "  (1, -0.07630691187392216, 2, 1),\n",
       "  (1, -0.07630691187392216, 2, 1),\n",
       "  (1, -0.13506979847186032, 2, 1),\n",
       "  (1, 0.05152813967246959, 2, 1),\n",
       "  (1, -0.13953715242375034, 3, 1),\n",
       "  (1, 0.020600304620923195, 2, 1),\n",
       "  (1, -0.07630691187392216, 2, 1),\n",
       "  (1, -0.07355777098045138, 2, 1),\n",
       "  (1, 0.20135631836662765, 3, 1),\n",
       "  (1, -0.07630691187392216, 2, 1),\n",
       "  (1, -0.07355777098045138, 3, 1),\n",
       "  (1, 0.04465528743879261, 3, 1),\n",
       "  (1, 0.05049721183741804, 2, 1),\n",
       "  (1, 0.31042848331508127, 4, 2),\n",
       "  (1, -0.11891859572271941, 4, 2),\n",
       "  (1, 0.04465528743879261, 2, 1),\n",
       "  (1, 0.16836662764497817, 4, 1),\n",
       "  (1, 0.017163878504084705, 3, 1),\n",
       "  (1, -0.010671173042307048, 4, 2),\n",
       "  (1, -0.1477845751041627, 3, 1),\n",
       "  (1, 0.02403673073776168, 3, 2),\n",
       "  (1, 0.08932882695769295, 3, 2),\n",
       "  (1, 0.07283398159686821, 4, 1),\n",
       "  (1, -0.010327530430623198, 3, 1),\n",
       "  (1, -0.010327530430623198, 3, 1),\n",
       "  (1, 0.046579686064222164, 4, 1),\n",
       "  (1, 0.0034181740367307534, 3, 1),\n",
       "  (1, 0.02403673073776168, 3, 1),\n",
       "  (1, 0.08245597472401597, 3, 2),\n",
       "  (1, 0.21304016716387852, 3, 2),\n",
       "  (1, 0.05840099190614656, 3, 1),\n",
       "  (1, 0.17523947987865515, 3, 2),\n",
       "  (1, 0.2563391362360435, 3, 2),\n",
       "  (1, 0.2563391362360435, 2, 1),\n",
       "  (1, 0.09139068262779605, 3, 2),\n",
       "  (1, 0.12712951424291632, 3, 2),\n",
       "  (1, 0.25599549362435964, 3, 1),\n",
       "  (1, 0.13778243520511563, 3, 2),\n",
       "  (1, 0.26183741802298505, 4, 4),\n",
       "  (1, 0.15118449706078574, 2, 1),\n",
       "  (1, -0.08936533111790843, 2, 1),\n",
       "  (1, 0.12712951424291632, 3, 1),\n",
       "  (1, 0.18005047644222905, 2, 1),\n",
       "  (1, 0.15737006407109502, 3, 2),\n",
       "  (1, 0.1614937754113012, 3, 3),\n",
       "  (1, 0.20273088881336307, 4, 1),\n",
       "  (1, -0.08592890500106994, 3, 1),\n",
       "  (1, -0.14984643077426582, 3, 1),\n",
       "  (1, -0.1477845751041627, 3, 1),\n",
       "  (1, 0.3676793424216105, 2, 1),\n",
       "  (1, 0.02403673073776168, 3, 2),\n",
       "  (1, -0.04469179159900808, 3, 1),\n",
       "  (1, -0.08936533111790843, 3, 1),\n",
       "  (1, -0.07012134486361289, 3, 2),\n",
       "  (1, -0.07589454073990155, 3, 1),\n",
       "  (1, -0.07362649950278814, 3, 1),\n",
       "  (1, -0.07905605276739296, 3, 1),\n",
       "  (1, 0.32369308812607783, 3, 1),\n",
       "  (1, 0.12712951424291632, 3, 1),\n",
       "  (1, 0.19448346613295067, 3, 1),\n",
       "  (1, 0.11338380977556237, 2, 1),\n",
       "  (1, -0.05843749606636203, 6, 2),\n",
       "  (1, 0.35180305376181664, 3, 1),\n",
       "  (1, 0.06527384413982354, 3, 1),\n",
       "  (1, 0.08726697128758985, 3, 2),\n",
       "  (1, 0.4769576929370744, 4, 2),\n",
       "  (1, 0.09963810530820842, 3, 1),\n",
       "  (1, 0.09963810530820842, 4, 2),\n",
       "  (1, 0.23572057953501255, 4, 3),\n",
       "  (1, 0.3305659403597548, 3, 2),\n",
       "  (1, 0.38142504688896445, 3, 1),\n",
       "  (1, 0.7181948063391362, 3, 1),\n",
       "  (1, 0.5532463527308888, 2, 1),\n",
       "  (1, 0.2645865589164558, 4, 2),\n",
       "  (1, 0.1924216104628476, 5, 2),\n",
       "  (1, 0.7594319197411981, 5, 3),\n",
       "  (1, 0.06527384413982354, 3, 2),\n",
       "  (1, 0.08314325994738367, 3, 1),\n",
       "  (1, 0.08726697128758985, 3, 1),\n",
       "  (1, 0.08314325994738367, 4, 2),\n",
       "  (1, 0.09551439396800224, 4, 2),\n",
       "  (1, 0.08726697128758985, 3, 2),\n",
       "  (1, 0.09620167919136993, 4, 2),\n",
       "  (1, 0.04121886132195412, 3, 2),\n",
       "  (1, 0.15599549362435963, 4, 2),\n",
       "  (1, 0.13812607781679948, 3, 1),\n",
       "  (1, -0.07905605276739296, 3, 2),\n",
       "  (1, 0.2645865589164558, 4, 2),\n",
       "  (1, 0.09620167919136993, 3, 1)])"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_train_scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ff9c0",
   "metadata": {},
   "source": [
    "## Function to find slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "df307dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Slope(theta, X, Y, ind):\n",
    "\tslope = 0\n",
    "\tfor i in range(len(X)):\n",
    "\t\titr = 0\n",
    "\t\tfor j in range(len(theta)):\n",
    "\t\t\titr = itr + theta[j] * X[i][j]\n",
    "\t\tslope += (itr - Y[i]) * X[i][ind]\n",
    "\treturn slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e54a4",
   "metadata": {},
   "source": [
    "# Using batch gradient without feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "504904d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0000001\n",
    "theta = np.zeros((1,4))\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "7b985540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.39331599, 6.39331599, 6.39331599, 6.39331599]])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    temp = theta.copy()\n",
    "    for j in range(len(theta)):\n",
    "        temp[j] -= (lr/n_train) * Slope(theta, X_train, Y_train, j)\n",
    "    theta = temp.copy()\n",
    "np.reshape(theta, (4,1))\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "5584ac52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta.reshape((4,1))\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "0e051880",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.dot(X_test, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "5caf25a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5017827139124416"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = 0\n",
    "for i in range(n_test-1):\n",
    "    error += abs((Y_test.iloc[i] - Y_pred[i][0])/Y_test.iloc[i])\n",
    "error /= n_test\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53ca70a",
   "metadata": {},
   "source": [
    "# Using batch gradient with feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "c7ddedc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.002\n",
    "theta = np.zeros((1,4))\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "dfa0b3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11600.1768945, 11600.1768945, 11600.1768945, 11600.1768945]])"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    temp = theta.copy()\n",
    "    for j in range(len(theta)):\n",
    "        temp[j] -= (lr/n_train) * Slope(theta, X_train_scaling, Y_train_scaling, j)\n",
    "    theta = temp.copy()\n",
    "np.reshape(theta, (4,1))\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "6837bd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = theta.reshape((4,1))\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "caf401b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21904970666282153"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = np.dot(X_test_scaling, theta)\n",
    "error = 0\n",
    "for i in range(n_test-1):\n",
    "    error += abs((Y_test.iloc[i] - Y_pred[i][0])/Y_test.iloc[i])\n",
    "error /= n_test\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ee6aa",
   "metadata": {},
   "source": [
    "# Using Stochastic gradient without feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "f7052720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SlopeStoch(theta,X,Y,ind):\n",
    "\titr = 0\n",
    "\tfor j in range(len(theta)):\n",
    "\t\titr = itr + theta[j] * X[j]\n",
    "\treturn (itr - Y) * X[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "c2d40f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.002\n",
    "theta = [0,0,0,0]\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "0e486e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[66269.83327489161, 0, 0, 0]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for iter in range(10):\n",
    "\tfor i in range(len(X_train)):\n",
    "\t\ttempp = theta.copy()\n",
    "\t\tfor j in range(len(temp)):\n",
    "\t\t\ttempp[j] = tempp[j] - (lr * SlopeStoch(theta, X_train[i], Y_train[i], j))\n",
    "\t\ttheta = tempp.copy()\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "56a367ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.dot(X_test, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "3a84d4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22545121631832774"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = 0\n",
    "for i in range(n_test-1):\n",
    "    error += abs((Y_test.iloc[i] - Y_pred[i])/Y_test.iloc[i])\n",
    "error = error/n_test\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd7f78",
   "metadata": {},
   "source": [
    "# Using Stochastic gradient with feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "0e378747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.000003\n",
    "theta = [0,0,0,0]\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "6e1c007c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[685.7678766874692, 5.893634578291078, 2100.5757460708946, 958.624260916667]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for iter in range(10):\n",
    "\tfor i in range(len(X_train_scaling)):\n",
    "\t\ttempp = theta.copy()\n",
    "\t\tfor j in range(4):\n",
    "\t\t\ttempp[j] = tempp[j] - (lr * (SlopeStoch(theta, X_train_scaling[i], Y_train_scaling[i], j)))\n",
    "\t\ttheta = tempp.copy()\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "01381424",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.dot(X_test, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "f816c67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43491568188402463"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = 0\n",
    "for i in range(n_test-1):\n",
    "    error += abs((Y_test.iloc[i] - Y_pred[i])/Y_test.iloc[i])\n",
    "error = error/n_test\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe98606",
   "metadata": {},
   "source": [
    "# Using Minibatch gradient without feature scaling for batch size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "11854aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSize = 20;\n",
    "lr = 0.000000001\n",
    "theta = [0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "8941775e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Batches = math.ceil(len(X_train) / BatchSize)\n",
    "Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "d54126a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "equallyDiv = False\n",
    "if (len(Y_train) % BatchSize == 0):\n",
    "\tequallyDiv = True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "09f9a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "\tfor batch in range(Batches):\n",
    "\t\ttemp = [0, 0, 0, 0]\n",
    "\t\tfor j in range(len(theta)):\n",
    "\t\t\tfor i in range(BatchSize):\n",
    "\t\t\t\tif (batch * BatchSize + i == len(X_train)):\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tpred = 0.0\n",
    "\t\t\t\tfor wj in range(len(theta)):\n",
    "\t\t\t\t\tpred += theta[wj] * X_train[batch * BatchSize + i][wj]\n",
    "\t\t\t\tpred -= Y_train[batch * BatchSize + i]\n",
    "\t\t\t\tpred *= X_train[batch * BatchSize + i][j]\n",
    "\t\t\t\ttemp[j] += pred;\n",
    "\n",
    "\t\tif (not equallyDiv and batch == Batches - 1):\n",
    "\t\t\tfor j in range(len(temp)):\n",
    "\t\t\t\ttheta[j] -= (temp[j] / (len(Y_train) % BatchSize)) * lr\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(temp)):\n",
    "\t\t\t\ttheta[j] -= (temp[j] / BatchSize) * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "76afc161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0046877609132215045,\n",
       " 12.601042025875056,\n",
       " 0.0163743583721716,\n",
       " 0.00829941066841396]"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "18bd7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.dot(X_test, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "7b004105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2984284750975368"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = 0\n",
    "for i in range(n_test-1):\n",
    "    error += abs((Y_test.iloc[i] - Y_pred[i])/Y_test.iloc[i])\n",
    "error = error/n_test\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a5416",
   "metadata": {},
   "source": [
    "# Using Minibatch gradient with feature scaling for batch size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "f920995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSize = 20;\n",
    "lr = 0.00002\n",
    "theta = [0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "c7887ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batches = math.ceil(len(X_train_scaling) / BatchSize)\n",
    "equallyDiv = False\n",
    "if (len(Y_train_scaling) % BatchSize == 0):\n",
    "\tequallyDiv = True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "b4b8f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "\tfor batch in range(Batches):\n",
    "\t\ttemp = [0, 0, 0, 0]\n",
    "\t\tfor j in range(len(theta)):\n",
    "\t\t\tfor i in range(BatchSize):\n",
    "\t\t\t\tif (batch * BatchSize + i == len(X_train_scaling)):\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tpred = 0.0\n",
    "\t\t\t\tfor wj in range(len(theta)):\n",
    "\t\t\t\t\tpred += theta[wj] * X_train_scaling[batch * BatchSize + i][wj]\n",
    "\t\t\t\tpred -= Y_train_scaling[batch * BatchSize + i]\n",
    "\t\t\t\tpred *= X_train_scaling[batch * BatchSize + i][j]\n",
    "\t\t\t\ttemp[j] += pred;\n",
    "\n",
    "\t\tif (not equallyDiv and batch == Batches - 1):\n",
    "\t\t\tfor j in range(len(temp)):\n",
    "\t\t\t\ttheta[j] -= (temp[j] / (len(Y_train_scaling) % BatchSize)) * lr\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(temp)):\n",
    "\t\t\t\ttheta[j] -= (temp[j] / BatchSize) * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "7be4393b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[737.0312224997455, 15.818366536564183, 2280.3034424443404, 1034.8610259078293]"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "c63f9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.dot(X_test, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "c68ca650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43735434315618654"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = 0\n",
    "for i in range(n_test-1):\n",
    "    error += abs((Y_test.iloc[i] - Y_pred[i])/Y_test.iloc[i])\n",
    "error = error/n_test\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce2ebab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a9b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
